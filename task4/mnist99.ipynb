{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST 99%+\n",
    "Current settings result in the test accuracy crusing above 99.5%.\n",
    "\n",
    "Final settings overview:\n",
    "\n",
    "- 3 conv layers (6/5/4 kernels, 24/48/64 channels, 1/2/2 stride, no dropout)\n",
    "- 2 dense (200/10 neurons, .75 dropout keep probability on the first)\n",
    "- batch normalization on all layers, 0.999 decay\n",
    "- decaying learning rate from 0.02 to 0.00015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from numpy.random import choice, random_integers\n",
    "from mnist import MNIST\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "data = MNIST()\n",
    "BATCHSIZE = 100\n",
    "EPOCHS = 15000\n",
    "TESTSTEPSIZE = 100\n",
    "\n",
    "RATE_MAX = 0.02\n",
    "RATE_MIN = 0.00015\n",
    "RATE_DECAY = 1000\n",
    "\n",
    "DROPOUT = 0.75\n",
    "DROPOUT_CONV = 0.75\n",
    "\n",
    "K = 24\n",
    "L = 48\n",
    "M = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batchnorm(y, is_test, iteration, offset, convolutional=False):\n",
    "    exp_moving_avg = tf.train.ExponentialMovingAverage(0.999, iteration)\n",
    "    mean, variance = tf.nn.moments(y, [0, 1, 2] if convolutional else [0])\n",
    "    update_moving_avgs = exp_moving_avg.apply([mean, variance])\n",
    "    m = tf.cond(is_test, lambda: exp_moving_avg.average(mean), lambda: mean)\n",
    "    v = tf.cond(is_test, lambda: exp_moving_avg.average(variance), lambda: variance)\n",
    "    ybn = tf.nn.batch_normalization(y, m, v, offset, None, 1e-5)\n",
    "    return ybn, update_moving_avgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, (None, 28, 28), name='input')\n",
    "t = tf.placeholder(tf.int64, (None), name='target')\n",
    "lr = tf.placeholder(tf.float32)\n",
    "it = tf.placeholder(tf.int32)\n",
    "tst = tf.placeholder(tf.bool)\n",
    "drate = tf.placeholder(tf.float32)\n",
    "drate_conv = tf.placeholder(tf.float32)\n",
    "\n",
    "x_ = tf.reshape(x, (-1,28,28,1))\n",
    "\n",
    "w0 = tf.Variable(tf.truncated_normal((6,6,1,K), stddev=0.1))\n",
    "b0 = tf.Variable(tf.ones((K,))/100)\n",
    "c0 = tf.nn.conv2d(x_, w0, (1,1,1,1), 'SAME')\n",
    "n0, u0 = batchnorm(c0, tst, it, b0, convolutional=True)\n",
    "y0 = tf.nn.relu(n0)\n",
    "\n",
    "w1 = tf.Variable(tf.truncated_normal((5,5,K,L), stddev=0.1))\n",
    "b1 = tf.Variable(tf.ones((L,))/100)\n",
    "c1 = tf.nn.conv2d(y0, w1, (1,2,2,1), 'SAME')\n",
    "n1, u1 = batchnorm(c1, tst, it, b1, convolutional=True)\n",
    "y1 = tf.nn.relu(n1)\n",
    "\n",
    "w2 = tf.Variable(tf.truncated_normal((4,4,L,M), stddev=0.1))\n",
    "b2 = tf.Variable(tf.ones((M,))/100)\n",
    "c2 = tf.nn.conv2d(y1, w2, (1,2,2,1), 'SAME')\n",
    "n2, u2 = batchnorm(c2, tst, it, b2, convolutional=True)\n",
    "y2 = tf.nn.relu(n2)\n",
    "\n",
    "y2_ = tf.reshape(y2, (-1,7*7*M))\n",
    "\n",
    "w3 = tf.Variable(tf.truncated_normal((7*7*M,200), stddev=0.1))\n",
    "b3 = tf.Variable(tf.ones((200,))/10)\n",
    "n3, u3 = batchnorm(tf.matmul(y2_, w3), tst, it, b3)\n",
    "y3 = tf.nn.relu(n3)\n",
    "y3 = tf.nn.dropout(y3, drate)\n",
    "\n",
    "wo = tf.Variable(tf.truncated_normal((200,10), stddev=0.1))\n",
    "bo = tf.Variable(tf.zeros((10,)))\n",
    "y = tf.matmul(y3, wo) + bo\n",
    "\n",
    "update_ema = tf.group(u0, u1, u2, u3)\n",
    "\n",
    "entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(y, t)\n",
    "entropy = tf.reduce_mean(entropy) * 100\n",
    "train_step = tf.train.AdamOptimizer(lr).minimize(entropy)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), t)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Viz:\n",
    "    test_acc = []\n",
    "    test_loss = []\n",
    "    learning_rate = []\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.fig = plt.figure('Training...', figsize=(9,7.5))\n",
    "        self.ax1 = self.fig.add_subplot(221)\n",
    "        self.ax2 = self.fig.add_subplot(222)\n",
    "        self.ax3 = self.fig.add_subplot(223)\n",
    "\n",
    "        self.ax1.set_xlim([0, EPOCHS])\n",
    "        self.ax1.set_ylim([0, 100])\n",
    "        self.ax2.set_xlim([0, EPOCHS])\n",
    "        self.ax2.set_ylim([0, 100])\n",
    "        self.ax3.set_xlim([0, EPOCHS])\n",
    "        self.ax3.set_ylim([0, RATE_MAX*1.25])\n",
    "\n",
    "        self.plt1, = self.ax1.plot([0], [0])\n",
    "        self.plt2, = self.ax2.plot([0], [0])\n",
    "        self.plt3, = self.ax3.plot([RATE_MAX], [0])\n",
    "        plt.show()\n",
    "\n",
    "    def update(self, i, learning_rate, test_acc, test_loss):\n",
    "        step = len(self.test_acc) + 1\n",
    "        test_acc = test_acc * 100\n",
    "        self.test_acc.append(test_acc)\n",
    "        self.test_loss.append(test_loss)\n",
    "        self.learning_rate.append(learning_rate)\n",
    "\n",
    "        if i == EPOCHS:\n",
    "            self.fig.canvas.set_window_title('Training done.')\n",
    "            self.fig.suptitle('Training done. Max test accuracy {:.2f}% and min loss {:.2f}.'\n",
    "                .format(np.max(self.test_acc), np.min(self.test_loss)))\n",
    "        else:\n",
    "            self.fig.canvas.set_window_title('Training...')\n",
    "            self.fig.suptitle( '{:.2f}% (epoch {} of {}) done. Max test accuracy {:.2f}% and min loss {:.2f}.'\n",
    "                .format((i/EPOCHS)*100, i, EPOCHS, np.max(self.test_acc), np.min(self.test_loss)))\n",
    "\n",
    "        self.ax1.set_title('Test accuracy {:.2f}%'.format(test_acc))\n",
    "        self.ax1.set_ylim([np.round(test_acc)-10, 100])\n",
    "        self.ax1.set_xlim([0, np.min([i+100, EPOCHS])])\n",
    "        self.plt1.set_ydata(self.test_acc)\n",
    "        self.plt1.set_xdata(np.arange(step)*TESTSTEPSIZE)\n",
    "\n",
    "        self.ax2.set_title('Test loss {:.2f}'.format(test_loss))\n",
    "        self.ax2.set_ylim([0, np.round(test_loss)+10])\n",
    "        self.ax2.set_xlim([0, np.min([i+100, EPOCHS])])\n",
    "        self.plt2.set_ydata(self.test_loss)\n",
    "        self.plt2.set_xdata(np.arange(step)*TESTSTEPSIZE)\n",
    "        \n",
    "        self.ax3.set_title('Learning Rate {:.8f}'.format(learning_rate))\n",
    "        self.ax3.set_xlim([0, np.min([i+100, EPOCHS])])\n",
    "        self.plt3.set_ydata(self.learning_rate)\n",
    "        self.plt3.set_xdata(np.arange(step)*TESTSTEPSIZE)\n",
    "        \n",
    "        self.fig.canvas.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "viz = Viz()\n",
    "\n",
    "for i in range(0, EPOCHS + 1):\n",
    "    batch_x, batch_t = data.getTrainingBatch(BATCHSIZE)\n",
    "    rate = RATE_MIN + (RATE_MAX - RATE_MIN) * np.exp(-i/RATE_DECAY)\n",
    "    \n",
    "    sess.run(train_step, {\n",
    "        x: batch_x, t: batch_t, lr: rate, tst: False, drate: DROPOUT, drate_conv: DROPOUT_CONV\n",
    "    })\n",
    "    sess.run(update_ema, {x: batch_x, t: batch_t, tst: False, it: i, drate: 1, drate_conv: 1})\n",
    "    if i % TESTSTEPSIZE == 0:\n",
    "        test_acc, test_loss = sess.run([accuracy, entropy], {\n",
    "            x: data.testData, t: data.testLabels, tst: True, drate: 1, drate_conv: 1\n",
    "        })\n",
    "        viz.update(i, rate, test_acc, test_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize some of the failed predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "predictions, correctness = sess.run([y, correct_prediction], {\n",
    "    x: data.testData, t: data.testLabels, tst: True, drate: 1, drate_conv: 1\n",
    "})\n",
    "predictions = np.argmax(predictions, 1)\n",
    "s = correctness == False\n",
    "\n",
    "plt.figure('wrong predictions', figsize=(10, 15))\n",
    "\n",
    "for i, (img, label, pred) in enumerate(zip(data.testData[s], data.testLabels[s], predictions[s])):\n",
    "    if i >= 50:\n",
    "        break\n",
    "    ax = plt.subplot(10, 5, i+1)\n",
    "    ax.set_title('saw {}, is {}'.format(pred, label))\n",
    "    ax.imshow(img, cmap='gray')\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
