{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Network Structure\n",
    "How many neurons are simulated? \n",
    "\n",
    "How many degrees of freedom (weights) does the network have?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "-- answers missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from numpy.random import choice, random_integers\n",
    "from mnist import MNIST\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "data = MNIST()\n",
    "BATCHSIZE = 100\n",
    "EPOCHS = 10000\n",
    "TESTSTEPSIZE = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batchnorm(y, is_test, iteration, offset, convolutional=False):\n",
    "    exp_moving_avg = tf.train.ExponentialMovingAverage(0.9999, iteration)\n",
    "    mean, variance = tf.nn.moments(y, [0, 1, 2] if convolutional else [0])\n",
    "    update_moving_avgs = exp_moving_avg.apply([mean, variance])\n",
    "    m = tf.cond(is_test, lambda: exp_moving_avg.average(mean), lambda: mean)\n",
    "    v = tf.cond(is_test, lambda: exp_moving_avg.average(variance), lambda: variance)\n",
    "    ybn = tf.nn.batch_normalization(y, m, v, offset, None, 1e-5)\n",
    "    return ybn, update_moving_avgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, (None, 28, 28), name='input')\n",
    "t = tf.placeholder(tf.int64, (None), name='target')\n",
    "lr = tf.placeholder(tf.float32)\n",
    "it = tf.placeholder(tf.int32)\n",
    "tst = tf.placeholder(tf.bool)\n",
    "\n",
    "x_ = tf.reshape(x, (-1,28,28,1))\n",
    "\n",
    "w0 = tf.Variable(tf.truncated_normal((6,6,1,6), stddev=0.1))\n",
    "b0 = tf.Variable(tf.ones((6,))/10)\n",
    "c0 = tf.nn.conv2d(x_, w0, (1,1,1,1), 'SAME')\n",
    "n0, u0 = batchnorm(c0, tst, it, b0, convolutional=True)\n",
    "y0 = tf.nn.relu(n0)\n",
    "\n",
    "w1 = tf.Variable(tf.truncated_normal((5,5,6,12), stddev=0.1))\n",
    "b1 = tf.Variable(tf.ones((12,))/10)\n",
    "c1 = tf.nn.conv2d(y0, w1, (1,2,2,1), 'SAME')\n",
    "n1, u1 = batchnorm(c1, tst, it, b1, convolutional=True)\n",
    "y1 = tf.nn.relu(n1)\n",
    "\n",
    "w2 = tf.Variable(tf.truncated_normal((4,4,12,24), stddev=0.1))\n",
    "b2 = tf.Variable(tf.ones((24,))/10)\n",
    "c2 = tf.nn.conv2d(y1, w2, (1,2,2,1), 'SAME')\n",
    "n2, u2 = batchnorm(c2, tst, it, b2, convolutional=True)\n",
    "y2 = tf.nn.relu(n2)\n",
    "\n",
    "w3 = tf.Variable(tf.truncated_normal((7*7*24,200), stddev=0.1))\n",
    "b3 = tf.Variable(tf.ones((200,))/10)\n",
    "y2_ = tf.reshape(y2, (-1,7*7*24))\n",
    "n3, u3 = batchnorm(tf.matmul(y2_, w3), tst, it, b3)\n",
    "r3 = tf.nn.relu(n3)\n",
    "y3 = tf.nn.dropout(r3, 0.75)\n",
    "\n",
    "wo = tf.Variable(tf.truncated_normal((200,10), stddev=0.1))\n",
    "bo = tf.Variable(tf.zeros((10,)))\n",
    "y = tf.matmul(y3, wo) + bo\n",
    "\n",
    "update_ema = tf.group(u0, u1, u2, u3)\n",
    "\n",
    "entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(y, t)\n",
    "entropy = tf.reduce_mean(entropy) * 100\n",
    "train_step = tf.train.AdamOptimizer(lr).minimize(entropy)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), t)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "rate_max = 0.003\n",
    "rate_min = 0.0001\n",
    "rate_decay = 2000\n",
    "\n",
    "for i in range(1, EPOCHS + 1):\n",
    "    batch_x, batch_t = data.getTrainingBatch(10)\n",
    "    rate = rate_min + (rate_max - rate_min) * np.exp(-i/rate_decay)\n",
    "    \n",
    "    sess.run(train_step, {x: batch_x, t: batch_t, lr: rate, tst: False})\n",
    "    sess.run(update_ema, {x: batch_x, t: batch_t, tst: False, it: i})\n",
    "    if i % 100 == 0:\n",
    "        acc = sess.run(accuracy, {x: data.testData, t: data.testLabels, tst: True})\n",
    "        print(i, acc, rate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
