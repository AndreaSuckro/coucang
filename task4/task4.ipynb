{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Network Structure\n",
    "How many neurons are simulated? \n",
    "\n",
    "How many degrees of freedom (weights) does the network have?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "-- answers missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from numpy.random import choice, random_integers\n",
    "from mnist import MNIST\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "data = MNIST()\n",
    "BATCHSIZE = 100\n",
    "EPOCHS = 10000\n",
    "TESTSTEPSIZE = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, (None, 28, 28), name='input')\n",
    "t = tf.placeholder(tf.int64, (None), name='target')\n",
    "\n",
    "wght_i = tf.Variable(tf.truncated_normal((5,5,1,32), stddev=0.1), name='kernel')\n",
    "bias_i = tf.Variable(tf.constant(0.1, shape=(32,)), name='biases')\n",
    "conv_i = tf.nn.conv2d(tf.reshape(x, (-1,28,28,1)), wght_i, (1,1,1,1), 'SAME', name='convolution')\n",
    "acti_i = tf.tanh(conv_i + bias_i, name='activation')\n",
    "pool_i = tf.nn.max_pool(acti_i, (1,2,2,1), (1,2,2,1), 'SAME', name='pool')\n",
    "\n",
    "wght_h = tf.Variable(tf.truncated_normal((5,5,32,64), stddev=0.1), name='kernel')\n",
    "bias_h = tf.Variable(tf.constant(0.1, shape=(64,)), name='biases')\n",
    "conv_h = tf.nn.conv2d(pool_i, wght_h, (1,1,1,1), 'SAME', name='convolution')\n",
    "acti_h = tf.tanh(conv_h + bias_h, name='activation')\n",
    "pool_h = tf.nn.max_pool(acti_h, (1,2,2,1), (1,2,2,1), 'SAME', name='pool')\n",
    "\n",
    "\n",
    "wght_oh = tf.Variable(tf.random_normal((7*7*64,1024)), name='readout_hidden_weights')\n",
    "bias_oh = tf.Variable(tf.zeros((1024,)), name='readout_hidden_biases')\n",
    "read_oh = tf.nn.relu(tf.matmul(tf.reshape(pool_h, (-1,7*7*64)), wght_oh) + bias_oh, name='readout_hidden')\n",
    "\n",
    "wght_o = tf.Variable(tf.random_normal((1024,10)), name='weights')\n",
    "bias_o = tf.Variable(tf.zeros((10,)), name='biases')\n",
    "y = tf.matmul(read_oh, wght_o) + bias_o\n",
    "\n",
    "\n",
    "entropy = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(y, t), name='entropy')\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(entropy)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), t)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.initialize_all_variables())\n",
    "\n",
    "plt.ion()\n",
    "figs, ax = plt.subplots(1, 1)\n",
    "plt.title('Training...')\n",
    "acc = []\n",
    "\n",
    "for i in range(1, EPOCHS + 1):\n",
    "    batch_x, batch_t = data.getTrainingBatch(10)\n",
    "    sess.run(train_step, {x: batch_x, t: batch_t})\n",
    "    if i % 100 == 0:\n",
    "        print(sess.run(accuracy, {x: data.testData, t: data.testLabels}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
